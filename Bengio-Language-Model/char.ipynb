{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from the dataset\n",
    "\n",
    "with open('../data/russian-novels/WAP.txt', 'r', encoding='utf-8-sig') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "chars = sorted(list(set(text)))\n",
    "ctoi = {c: i+1 for i, c in enumerate(chars)}\n",
    "ctoi['_'] = 0\n",
    "itoc = {i: c for c, i in ctoi.items()}\n",
    "\n",
    "encode = lambda x: torch.tensor([ctoi[c] for c in x], dtype=torch.long)\n",
    "decode = lambda x: ''.join([itoc[i.item()] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2566610, 8]), torch.Size([2566610]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dataset\n",
    "block_size = 8\n",
    "\n",
    "X, Y = [], []\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "test = text[int(len(text) * 0.8):]\n",
    "text = text[:int(len(text) * 0.8)]\n",
    "\n",
    "for i in range(0, len(text) - block_size):\n",
    "    X.append([ctoi[c] for c in text[i:i+block_size]])\n",
    "    Y.append(ctoi[text[i+block_size]])\n",
    "\n",
    "for i in range(0, len(test) - block_size):\n",
    "    X_test.append([ctoi[c] for c in test[i:i+block_size]])\n",
    "    Y_test.append(ctoi[test[i+block_size]])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "Y_test = torch.tensor(Y_test)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size=32):\n",
    "    idx = torch.randint(0, X.size(0), (batch_size,))\n",
    "    return X[idx], Y[idx]\n",
    "\n",
    "def get_test_batch(batch_size=32):\n",
    "    idx = torch.randint(0, X_test.size(0), (batch_size,))\n",
    "    return X_test[idx], Y_test[idx]\n",
    "\n",
    "batch = get_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.C = torch.randn(len(chars)+1, 2)\n",
    "        self.W1 = torch.randn(block_size * 2, 200) * 0.2\n",
    "        self.b1 = torch.randn(200) * 0.01\n",
    "        self.W2 = torch.randn(200, len(chars)+1) * 0.01\n",
    "        self.b2 = torch.randn(len(chars)+1) * 0\n",
    "        self.parameters = [self.C, self.W1, self.b1, self.W2, self.b2] \n",
    "       \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        emb = self.C[x].view(-1, 2*block_size)\n",
    "        h = torch.relu(emb @ self.W1 + self.b1)\n",
    "        logits = h @ self.W2 + self.b2\n",
    "        preds = torch.softmax(logits, dim=1)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        \n",
    "        return preds, loss\n",
    "\n",
    "model = Model()\n",
    "\n",
    "for p in model.parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.501145362854004\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = batch\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters, lr=0.001, momentum=0.9)\n",
    "\n",
    "for i in range(99999):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    x, y = get_batch(32)\n",
    "    \n",
    "    outputs, loss = model(x, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    # if i % 1000 == 0:\n",
    "print(f'Loss: {loss.item()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the model\n",
    "\n",
    "result = encode(\"War and \")\n",
    "print(\"War and \", end='')\n",
    "while result[-1] != 0:\n",
    "    x = result[-8:]\n",
    "    x = x.view(1, -1)\n",
    "    y = torch.tensor([result[-1]])\n",
    "    preds, loss = model.forward(x, y)\n",
    "    next_char = torch.multinomial(preds[0], 1)\n",
    "    result = torch.cat([result, next_char])\n",
    "    print(decode(next_char) , end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2150869369506836\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "x, y = get_test_batch(32)\n",
    "outputs, loss = model(x, y)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
